{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d77393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agenda\n",
    "## What is the purpose of model evaluation, and what are some common evaluation procedures?\n",
    "## What is the usage of classification accuracy, and what are its limitations?\n",
    "## How does a confusion matrix describe the performance of a classifier?\n",
    "## What metrics can be computed from a confusion matrix?\n",
    "## How can you adjust classifier performance by changing the classification threshold?\n",
    "## What is the purpose of an ROC curve?\n",
    "## How does Area Under the Curve (AUC) differ from classification accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928ef740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review of model evaluation\n",
    "## Need a way to choose between models: different model types, tuning parameters, and features\n",
    "## Use a model evaluation procedure to estimate how well a model will generalize to out-of-sample data\n",
    "## Requires a model evaluation metric to quantify the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732c0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation procedures\n",
    "##Training and testing on the same data\n",
    "##Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "#Train/test split\n",
    "##Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "##Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "##Useful due to its speed, simplicity, and flexibility\n",
    "# K-fold cross-validation\n",
    "##Systematically create \"K\" train/test splits and average the results together\n",
    "##Even better estimate of out-of-sample performance\n",
    "##Runs \"K\" times slower than train/test spli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356df11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation metrics\n",
    "##Regression problems: Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "##Classification problems: Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18375efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6521262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f726b20",
   "metadata": {},
   "source": [
    "# Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a058746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "# as the url is not working need to download the dataset from kaggle\n",
    "col_names = ['pregnant','glucose',\"bp\",\"skin thickness\",'insulin',\"bmi\",'pedigree','age',\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e24ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv(r\"C:\\Users\\mynam\\Downloads\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2907c79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07c2cf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb58693",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['Pregnancies','Insulin','BMI','Age']\n",
    "X = pima[feature_col]\n",
    "Y = pima.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4be1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1688ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test ,Y_train ,Y_test = train_test_split(X,Y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f643013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698c3e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acf7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ff243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd7fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6c7a4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6a734",
   "metadata": {},
   "source": [
    "# we should always check the classifiaction accuracy with null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "645b4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null accuracy: accuracy that could be achived by predicting the most frequent class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c473798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()\n",
    "# examine the class distribution of the testing set (using a Pandas Series method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "253631e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "Y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e26edff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of zeros\n",
    "1 - Y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95e65117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "max(Y_test.mean(), 1 - Y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3825ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.677083\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "Y_test.value_counts().head(1) / len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "701a79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Comparing the true and predicted response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2966e1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', Y_test.values[0:25])\n",
    "print('Pred:', y_pred[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cf00653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion:\n",
    "##Classification accuracy is the easiest classification metric to understand\n",
    "##But, it does not tell you the underlying distribution of response values\n",
    "##And, it does not tell you what \"types\" of errors your classifier is making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4156e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the issue adressed by the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b245fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "## Table that describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "775b13a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  16]\n",
      " [ 46  16]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(Y_test, y_pred))\n",
    "# if u did it in reverse order the matrix will be reversed and no error will be raised this is because the \n",
    "# matrics in the sklearn model ascpect that the first value is the true value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93315180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in above the rows are representing the actual values [0] for 0  and [1] for 1\n",
    "# the column are representing the predticting values [0]is for 0  and [1] is for 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac956201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very observation in the testing set is represented in exactly one box\n",
    "#It's a 2x2 matrix because there are 2 response classes\n",
    "#The format shown here is not universal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac20a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic terminology\n",
    "\n",
    "#True Positives (TP): we correctly predicted that they do have diabetes\n",
    "#True Negatives (TN): we correctly predicted that they don't have diabetes\n",
    "#False Positives (FP): we incorrectly predicted that they do have diabetes (a \"Type I error\")\n",
    "#False Negatives (FN): we incorrectly predicted that they don't have diabetes (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee0d6e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', Y_test.values[0:25])\n",
    "print('Pred:', y_pred[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65b04956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(Y_test, y_pred)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ef8cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it help us to understand how well the classifier performed but does not help in understandinig which \n",
    "# model is the best \n",
    "# however there are many matrix which can be calculaated from the confusion matrix and those can be used in\n",
    "# the model selection procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079667c",
   "metadata": {},
   "source": [
    "# Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c8083fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6770833333333334\n",
      "0.6770833333333334\n"
     ]
    }
   ],
   "source": [
    "# Classification accuracy - how often our classifier correct ?\n",
    "print((TP + TN) / (TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ce65d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3229166666666667\n",
      "0.32291666666666663\n"
     ]
    }
   ],
   "source": [
    "# Classification Error: Overall, how often is the classifier incorrect?\n",
    "#Also known as \"Misclassification Rate\"\n",
    "print((FP + FN) / (TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d13e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25806451612903225\n",
      "0.25806451612903225\n"
     ]
    }
   ],
   "source": [
    "# Sensitivity: When the actual value is positive, how often is the prediction correct?\n",
    "\n",
    "# How \"sensitive\" is the classifier to detecting positive instances?\n",
    "# Also known as \"True Positive Rate\" or \"Recall\n",
    "\n",
    "print(TP / (TP + FN))\n",
    "print(metrics.recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf25c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8769230769230769\n"
     ]
    }
   ],
   "source": [
    "#Specificity: When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "#How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "\n",
    "print(TN / (TN + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef5d4e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12307692307692308\n"
     ]
    }
   ],
   "source": [
    "#False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
    "print(FP / (TN + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f289bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "#How \"precise\" is the classifier when predicting positive instances?\n",
    "print(TP / (TP + FP))\n",
    "print(metrics.precision_score(Y_test, y_pred))\n",
    "###Many other metrics can be computed: F1 score, Matthews correlation coefficient, et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion:\n",
    "##Confusion matrix gives you a more complete picture of how your classifier is performing\n",
    "##Also allows you to compute various classification metrics, and these metrics can guide your model selection\n",
    "#Which metrics should you focus on?\n",
    "\n",
    "#Choice of metric depends on your business objective\n",
    "#Spam filter (positive class is \"spam\"): Optimize for precision or specificity because false negatives \n",
    "# (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "#Fraudulent transaction detector (positive class is \"fraud\"): Optimize for sensitivity because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
