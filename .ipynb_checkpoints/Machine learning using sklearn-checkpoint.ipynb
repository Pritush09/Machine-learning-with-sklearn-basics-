{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d572dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris dataset\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291208dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "type(iris) # sklearn datatype for storing dataset and there atributes in sklearn Bunch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d39302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data) # one of the atributes is data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32fffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# each row is an observation known as sample\n",
    "# each column is a feature here in iris dataset has 4 column so 4 feature \n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8a6172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear discriminant analysis is used to make prediction on this dataset\n",
    "# if the dataset doesent have the species it can be classified into an unsupervised learning \n",
    "# by tempting to cluster the sample into meaningful groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d24030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.target) # print integrs representing the species of each observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62248d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# print the encoding scheme for species : 0=sestos 1=versicolour 2=verginica\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40131e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each value we are predicting is response ( also known as target, outcome, label, dependent variable )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1eb423",
   "metadata": {},
   "source": [
    "# the two type of supervised learning \n",
    "## classification - in which the responses is categorical (finite unordered set)\n",
    "## Regression - in which the responses are ordered and continuous \n",
    "\n",
    "### inorder to tell what we should carry on with calssification or regression \n",
    "### we have see the dataset and understand which would work the best for the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efde69",
   "metadata": {},
   "source": [
    "# Requierments for woking with  data in scikit-learn\n",
    " \n",
    " ##    1. feature and responses are seperate objects\n",
    " ##    2. feature and responses should be numeric \n",
    " ##    3. feature and reponses should be numpy arrays\n",
    " ##    4. feature and responses should have specific shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f805d592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# first we should check the type of features and reponses\n",
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6acc269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the data \n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbfab270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of responses (here it is one dimensional matching the number of observation)\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6222ab",
   "metadata": {},
   "source": [
    "# k nearest neighbours (knn) Classifaction maodel\n",
    "###   1. Pick value\n",
    "###   2. Search for the k observation in the training data that are nearest to the                          measurement of the unknown iris\n",
    "###   3. use the most popular response from the k nearest neighbour as the                            predicted response for the unknown iris \n",
    "\n",
    "the model basically calulate the numerical distanse  between the unknown iris and each of the 150 known iris and select the  5 known irises from the 150 which are the closest to the unknown irises \n",
    "and generally euclidean distance matrix is used to estimate the distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec94c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store feature matrix in x \n",
    "X = iris.data\n",
    "\n",
    "# store responses matrix in y\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "273f436d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4982da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4fed6",
   "metadata": {},
   "source": [
    "# Scikit learn 4 step modeling \n",
    "###  1. import the class u plan to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18a66ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we import he k neighbour classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6333e",
   "metadata": {},
   "source": [
    "##  2. 'instantiate' the 'estimator' \n",
    "##   i. estimator is a scikit learn 's term of model becz their primary role    is to estimate unknown quantities this process id called                           instantiation bcaz we are creating an instance of the k neighbor             classifier class \n",
    "##   ii. instantiate means make instance of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83abc4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1) # this is the parameter on which our model will take the \n",
    "# we can name as est or clf                   decisions ie here nearest ot the one data from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5efe87",
   "metadata": {},
   "source": [
    "## iii. name the object does not matter \n",
    "## iv. can specify the turning parameter (aka hyperparameter) during              this step\n",
    "## v. all parameter not specified are set to their defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba735aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=1)\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042547e1",
   "metadata": {},
   "source": [
    "# 3. Fix the model with data (aka 'model training')\n",
    "##   i. model is learning the relationship between X and Y\n",
    "##   ii. Occurs inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a89ac47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,Y) # this operation occur inplace bcz of which we dont have to assign it to another operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e69eff",
   "metadata": {},
   "source": [
    "# 4. Predict the response of the new observation\n",
    "##   i. New observation are called 'out of sample' data\n",
    "##   ii. Uses the information it learned during the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d14bce6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([[3,5,4,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9753d756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_it = [[3,5,4,2],[5,6,4,3]]\n",
    "knn.predict(predict_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72407d8a",
   "metadata": {},
   "source": [
    "# Using a different value for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "748f044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model with data \n",
    "est.fit(X,Y)\n",
    "\n",
    "est.predict(predict_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524e9ff",
   "metadata": {},
   "source": [
    "# Using different classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ffdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f64988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mynam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantate the model using default values\n",
    "logreg = LogisticRegression().fit(X,Y)\n",
    "# predict the response\n",
    "logreg.predict(predict_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc654e",
   "metadata": {},
   "source": [
    "# now to check which model is the best  k=1 , k=5 or logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31adac27",
   "metadata": {},
   "source": [
    "# first method to train and test on entire dataset\n",
    "## 1. train the model on entire dataset \n",
    "## 2. Test the model on the same dataset and evalute how well we did by comparing the predicted responses values with the true                     responses values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77b67f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting were we have ended from the last pricting cell were we have made some prediction\n",
    "logreg.predict(X)  # here we are predicting on the dataset itself as ro compare it with our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac60f080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg.predict(X)  # storing it in a new variable\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc05dcd",
   "metadata": {},
   "source": [
    "# Classification accuracy:\n",
    "##  1. proportion of correct prediction \n",
    "##  2. common evalution metric for for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72d423c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26fb6d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute classification accuracy for the logisticregression model\n",
    "metrics.accuracy_score(Y,y_pred)  # 97%\n",
    "# first arg is the responses we want , second the data on which we want o predict and check the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0157b6b",
   "metadata": {},
   "source": [
    "# for k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b15b887f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_k_5 = est.predict(X)\n",
    "metrics.accuracy_score(Y,y_for_k_5)   # 96%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708cf3b",
   "metadata": {},
   "source": [
    "# for k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "022f0c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_k_1 = knn.predict(X)\n",
    "metrics.accuracy_score(Y,y_for_k_1)  #100%\n",
    "# this will alway be 100% for this as it works on the closest distance from the original dataset \n",
    "# this is a very complex model which does not generalise as it has cought the noise in the data \n",
    "# rather than the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d2e841",
   "metadata": {},
   "source": [
    "# Problem with training and testing data \n",
    "##  1. goal to estimate likely performance of a model on out of sample             data\n",
    "##  2. But maximizing training accuracy rewards only over complex                 models that doesnt generalise\n",
    "##  3. unnecessarily complex models overfit the training data \n",
    "       picture in phone from data school 5 video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4963714",
   "metadata": {},
   "source": [
    "# Evaluation pricedure #2: train/ test split\n",
    "## 1. split the data set into two pieces : a training set and a testing set \n",
    "## 2. train the model on training set \n",
    "## 3. test the model on testing set and check how the model perfoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "739d8769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03428fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b387290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 to split into training data and testing data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a3792ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.4, random_state = 4)\n",
    "# now without mentioning the random_state this testing set will alway be changing everytime \n",
    "# we run the above command but after mentioning the random_state it will always have the same dataset \n",
    "# as the testing one \n",
    "########  photo in mobile data school choosing which model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5baa8",
   "metadata": {},
   "source": [
    "# What did this accomplish\n",
    "## 1. Model can be train and test on different data\n",
    "## 2. response value are known for training set and this prediction can be evaluated\n",
    "## 3. Testing accuracy is a better estimate than training accuracy of out of sample data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62bc7043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print the X_train and X_test shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10ebee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b1976de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2 = LogisticRegression()\n",
    "\n",
    "logreg2.fit(X_train,Y_train) # train the model on the given training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfc268a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "y_prediction_on_test_train_model_log = logreg2.predict(X_test)   \n",
    "\n",
    "print(metrics.accuracy_score(Y_test,y_prediction_on_test_train_model_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014531d1",
   "metadata": {},
   "source": [
    "# Repeat for k=5 for train test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e70fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_repeat_for_train_test_k5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_repeat_for_train_test_k5.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013fab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7210779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c575c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a17c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2aa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cde726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca6b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7460eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af40bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
