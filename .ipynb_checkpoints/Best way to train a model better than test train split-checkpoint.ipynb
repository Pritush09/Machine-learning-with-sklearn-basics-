{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ccba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f4c8d",
   "metadata": {},
   "source": [
    "# points to be covered in this are \n",
    "## drawback for train test split procedure for model evalution\n",
    "## K fold cross validation overcome the drawback of it \n",
    "## how can cross validation be used for tunning parameters choosing between the models and the feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2160e0",
   "metadata": {},
   "source": [
    "# NEed a eay to choose between ml models \n",
    "## and main goal is to estimate likely performance on the out of sample data\n",
    "# Initial idea : Train test the same model \n",
    "## but maximizing training accuracy rewards in over complex models which do not generalises and over fit the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93de08",
   "metadata": {},
   "source": [
    "# alterantive idea : Train Test split \n",
    "## split dataset into two spices one training the model and other for testing the model \n",
    "## testing accuracy is a better estimate then training accuracy of out of sample performance\n",
    "## But it provides a high variance since changing which observation happens to be in testing set can significantly change the testing accuracy meaning the testing accuracy can change a lot depending upon the what values are there in the testing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d127bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c4b5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris.data # this are the features \n",
    "Y = iris.target  # these are responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5826b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "X_train , X_test ,Y_train , Y_test = train_test_split(X,Y,random_state=4)# as the random state changes \n",
    "                                                                         # the output also changes out well in 2 it gives 100%\n",
    "# this is why the testing accuracy is a high variance estimate\n",
    "# check the classification accuracy of knn with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,Y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f469ae",
   "metadata": {},
   "source": [
    "# what if we create a bunch of train_test_split calculate the testing accuracy for each and averaged the result together\n",
    "\n",
    "# this is the essence of cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc2e9c",
   "metadata": {},
   "source": [
    "# steps for k-fold cross validation\n",
    "## 1. split the dataset into k equal partitions (or folds)\n",
    "## 2. use fold one as the testing set and the union of the other folds as the training set \n",
    "## 3.Calculate the testing accuracy \n",
    "## 4. repeat 2 and 3 K times , using a different fold asthe testing set each time \n",
    "## 5. USe the average testing accuracy as the estimate of out of sample accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f3083e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(25):\n",
    "    l.append(i)\n",
    "X_used_for_demonstration = np.array(l)\n",
    "print(X_used_for_demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2bf03dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of folds there are 5\n",
      "\n",
      "\n",
      "                  Training set observations                   Testing set observations\n",
      "[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]  [0 1 2 3 4]\n",
      "[ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]  [5 6 7 8 9]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]  [10 11 12 13 14]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]  [15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]  [20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "# Exaaample how to split a dataset \n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5,shuffle = False)   # True karoge toh no. shuffle hoga\n",
    "kf_used = kf.get_n_splits(25) # this is to just see how to split in new sklearn\n",
    "print(\"no. of folds there are \"+str(kf_used))\n",
    "print(\"\\n\")\n",
    "\n",
    "print('{:^61} {}'.format('Training set observations','Testing set observations'))\n",
    "for sett, data in kf.split(X_used_for_demonstration):\n",
    "    print(\"{}  {}\".format(sett,data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42827fdc",
   "metadata": {},
   "source": [
    "# 1. dataset 25 observations numbered from 0 to 24\n",
    "# 2. 5 fold cross validation thus it runs for 5 iterations\n",
    "# 3. for each iteration every observation in either of the dataset is are different \n",
    "# 4. every observstion in testing set is exactly once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82f36687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benifits of K fold cross validations\n",
    "## more accurate estimate of out of sample accuracy\n",
    "## more efficient use of data as every observation is used as both in training set and the testing set \n",
    "\n",
    "# Benifits of train test split method \n",
    "## it is K time faster \n",
    "## simpler to examione the detailed result of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984854e6",
   "metadata": {},
   "source": [
    "# Cross validation Recommendations\n",
    "## 1. K can be any no. , but k =10 is generally reccomended \n",
    "## 2. for classification problems , statified sampling is recommended for creating the folds\n",
    "### a. each response class should be represented with equal proportion in each of the k folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc492aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deebef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465906e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
